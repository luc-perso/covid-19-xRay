{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for local use\n",
    "db_work_dir = '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _mypath\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_cnn = 32\n",
    "batch_size_transformer = 32\n",
    "\n",
    "image_size = 256\n",
    "input_shape = (image_size, image_size, 1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "label_smoothing = 0.1\n",
    "lam_recon = 10.\n",
    "patience = 5\n",
    "min_delta = 0.005\n",
    "min_delta_fine_tuning = 0.0005\n",
    "\n",
    "# data augmentation\n",
    "scale = 1. / 255.\n",
    "flip = \"horizontal\"\n",
    "rotation_factor = 10. / 360.\n",
    "zoom_height_factor = 0.2\n",
    "zoom_width_factor = 0.2\n",
    "\n",
    "# vit\n",
    "patch_size = 1\n",
    "transformer_layers = 4\n",
    "num_heads = 8\n",
    "projection_dim = 64\n",
    "transformer_units_rate = [2, 1]\n",
    "mlp_head_units = [1024, 256]  # Size of the dense layers of the final classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpGXjB_lelbq"
   },
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1675006099424,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "HMe_zlMGelbq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 19:31:10.017710: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "augmentation = keras.Sequential(\n",
    "    [\n",
    "      layers.Rescaling(scale=scale),\n",
    "      layers.RandomFlip(flip),\n",
    "      layers.RandomRotation(rotation_factor),\n",
    "      layers.RandomZoom(height_factor=zoom_height_factor, width_factor=zoom_width_factor),\n",
    "    ],\n",
    "    name='augmentation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQeJmFhXelbq"
   },
   "source": [
    "cnn encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1675006102452,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "LOHNNFhrelbq"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "encoder = keras.Sequential(\n",
    "    [\n",
    "      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Conv2D(128, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Flatten(),\n",
    "    ],\n",
    "    name='encoder'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2RYqtjZelbr"
   },
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ppe7MFktelbr"
   },
   "outputs": [],
   "source": [
    "decoder = keras.Sequential(\n",
    "    [\n",
    "      layers.Dense(1024, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(np.prod(input_shape), activation='sigmoid'),\n",
    "      layers.Reshape(target_shape=input_shape),\n",
    "    ],\n",
    "    name='decoder'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aVIjXbtcelbr"
   },
   "outputs": [],
   "source": [
    "classifier = keras.Sequential(\n",
    "    [\n",
    "      layers.Dense(1024, activation='relu'),\n",
    "      layers.Dense(256, activation='relu'),\n",
    "      layers.Dense(3, activation='softmax'),\n",
    "    ],\n",
    "    name='classifier'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# for producing graph plot only\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "augmented = augmentation(inputs)\n",
    "encoded = encoder(augmented)\n",
    "decoded = decoder(encoded)\n",
    "classified = classifier(encoded)\n",
    "\n",
    "model_cnn_autoencoder = keras.Model(inputs=inputs, outputs=[classified, decoded])\n",
    "model_augmented = keras.Model(inputs=inputs, outputs=augmented)\n",
    "model_encoded = keras.Model(inputs=augmented, outputs=encoded)\n",
    "model_decoded = keras.Model(inputs=augmented, outputs=decoded)\n",
    "model_classified = keras.Model(inputs=encoded, outputs=classified)\n",
    "\n",
    "model_pure_cnn = keras.Model(inputs=inputs, outputs=classified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " augmentation (Sequential)      (None, 256, 256, 1)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " encoder (Sequential)           (None, 4096)         296512      ['augmentation[0][0]']           \n",
      "                                                                                                  \n",
      " classifier (Sequential)        (None, 3)            4458499     ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      " decoder (Sequential)           (None, 256, 256, 1)  21300480    ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,055,491\n",
      "Trainable params: 26,055,491\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cnn_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_encoder = keras.Sequential(name='shared_encoder')\n",
    "for layer in encoder.layers[:-1]:\n",
    "  shared_encoder.add(layer)\n",
    "\n",
    "from myLayers.vision_transformer import add_vit\n",
    "from myLayers.mlp import mlp\n",
    "\n",
    "# inputs = layers.Input(shape=input_shape)\n",
    "# augmented_transformer = augmentation(inputs)\n",
    "shared_encoded = shared_encoder(augmented)\n",
    "\n",
    "transformer_layers = 1\n",
    "features = add_vit(shared_encoded,\n",
    "            patch_size=patch_size,\n",
    "            input_image_size=shared_encoded.shape[1],\n",
    "            transformer_layers=transformer_layers,\n",
    "            num_heads=num_heads,\n",
    "            projection_dim=projection_dim,\n",
    "            transformer_units_rate=transformer_units_rate,\n",
    "            mlp_head_units=mlp_head_units)\n",
    "            \n",
    "# Classify outputs.\n",
    "softmax = layers.Dense(3, activation='softmax', kernel_initializer='random_normal')(features)\n",
    "\n",
    "# Create the Keras model\n",
    "model_cnn_transformer = keras.Model(inputs=inputs, outputs=softmax)\n",
    "\n",
    "model_shared_encoded = keras.Model(inputs=augmented, outputs=shared_encoded)\n",
    "model_transformer = keras.Model(inputs=shared_encoded, outputs=features)\n",
    "model_softmax = keras.Model(inputs=features, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 8, 8, 64)]   0           []                               \n",
      "                                                                                                  \n",
      " patches_1 (Patches)            (None, None, 64)     0           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " patch_encoder_1 (PatchEncoder)  (None, 64, 64)      8256        ['patches_1[1][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 64, 64)      128         ['patch_encoder_1[1][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 64, 64)      132672      ['layer_normalization_9[1][0]',  \n",
      " eadAttention)                                                    'layer_normalization_9[1][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 64, 64)       0           ['multi_head_attention_4[1][0]', \n",
      "                                                                  'patch_encoder_1[1][0]']        \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 64, 64)      128         ['add_8[1][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 64, 128)      8320        ['layer_normalization_10[1][0]'] \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 64, 128)      0           ['dense_21[1][0]']               \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 64, 64)       8256        ['dropout_11[1][0]']             \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 64, 64)       0           ['dense_22[1][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 64, 64)       0           ['dropout_12[1][0]',             \n",
      "                                                                  'add_8[1][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 64, 64)      128         ['add_9[1][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 4096)         0           ['layer_normalization_11[1][0]'] \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 4096)         0           ['flatten_2[1][0]']              \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 1024)         4195328     ['dropout_13[1][0]']             \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 1024)         0           ['dense_23[1][0]']               \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 256)          262400      ['dropout_14[1][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 256)          0           ['dense_24[1][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,615,616\n",
      "Trainable params: 4,615,616\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_transformer.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-19-xRay-gI8RPtYc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 15 2022, 05:25:54) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec449b28ee1275c8ed3472cdab9bc054b62d41bc2731e9c066fdcbfc125fb022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
