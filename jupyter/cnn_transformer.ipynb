{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aomJUY_gvXed",
   "metadata": {
    "id": "aomJUY_gvXed"
   },
   "source": [
    "Initialise code for google colab\n",
    "\n",
    "Mount google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GAjcLhjCgpxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4450,
     "status": "ok",
     "timestamp": 1671446275823,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "GAjcLhjCgpxv",
    "outputId": "e34c2966-478f-439f-c4bb-ea2036820438"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import tensorflow_addons as tfa\n",
    "print(tfa.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.11\n",
    "!pip install tensorflow-addons==0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J3iW3Uff2Jyh",
   "metadata": {
    "id": "J3iW3Uff2Jyh"
   },
   "source": [
    "Create data base files under google colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D1ubGnuD2CXZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88494,
     "status": "ok",
     "timestamp": 1671446369482,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "D1ubGnuD2CXZ",
    "outputId": "79fec16a-f91c-413d-f571-dd30d3435e5f"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/data_equalize.zip' -d '/content/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sMjhaRhC-HQM",
   "metadata": {
    "id": "sMjhaRhC-HQM"
   },
   "source": [
    "For Luc because my archive made on mac create a __MACOSX folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iAyxXHqB935f",
   "metadata": {
    "executionInfo": {
     "elapsed": 2940,
     "status": "ok",
     "timestamp": 1671446392319,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "iAyxXHqB935f"
   },
   "outputs": [],
   "source": [
    "%rm -rf /content/__MACOSX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "nnQuhv17x7hK",
   "metadata": {
    "id": "nnQuhv17x7hK"
   },
   "source": [
    "Define working directory to our jupyter repertory:\n",
    "* because path to the different repertories (./data, ./output...) are define relatevly to jupyter one\n",
    "* let import _mypath which add ./lib to python path in order to import our own define libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9WqQG1rjjHGq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1671446474973,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "9WqQG1rjjHGq",
    "outputId": "89a23162-4e46-4cd1-f96d-5c67bb7996aa"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/covid-19-xRay/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c135d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _mypath\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.path_origin_data import build_data_paths \n",
    "from database.path_origin_data import lung_name, infection_name\n",
    "from database.path_origin_data import train_name, test_name, valid_name\n",
    "from database.path_origin_data import normal_name, covid_name, no_covid_name\n",
    "from database.path_origin_data import images_name, lung_mask_name, infection_mask_name\n",
    "\n",
    "from database.dataset import build_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76855cab",
   "metadata": {
    "id": "76855cab"
   },
   "source": [
    "Build paths and variables for reading data base hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X9Ngq0q01zxH",
   "metadata": {
    "id": "X9Ngq0q01zxH"
   },
   "outputs": [],
   "source": [
    "# for local use\n",
    "db_path = '../data_equalize'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KsCYZqOl137k",
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1671446525765,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "KsCYZqOl137k"
   },
   "outputs": [],
   "source": [
    "# for google colab use\n",
    "db_path = '/content/data_equalize'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join('..', 'output')\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec096c7",
   "metadata": {
    "id": "fec096c7"
   },
   "source": [
    "Structure to manage paths in data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1271f47",
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1671446527378,
     "user": {
      "displayName": "Luc Thomas",
      "userId": "17860019511086541433"
     },
     "user_tz": -60
    },
    "id": "a1271f47"
   },
   "outputs": [],
   "source": [
    "data_paths = build_data_paths()\n",
    "idx = pd.IndexSlice\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tf Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = data_paths['path']\n",
    "\n",
    "ds_train = build_dataset(db_path, paths, db=[lung_name], ds=[train_name])\n",
    "ds_test = build_dataset(db_path, paths, db=[lung_name], ds=[test_name])\n",
    "ds_valid = build_dataset(db_path, paths, db=[lung_name], ds=[valid_name])\n",
    "ds_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 256\n",
    "input_shape = (image_size, image_size, 1)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "label_smoothing = 0.01\n",
    "\n",
    "# data augmentation\n",
    "scale = 1. / 255.\n",
    "flip = \"horizontal\"\n",
    "rotation_factor = 0.1\n",
    "zoom_height_factor = 0.2\n",
    "zoom_width_factor = 0.2\n",
    "\n",
    "# vit\n",
    "patch_size = 16\n",
    "input_image_size = image_size\n",
    "transformer_layers = 2\n",
    "num_heads = 4\n",
    "projection_dim = 64\n",
    "transformer_units_rate = [2, 1]\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_seq = keras.Sequential(\n",
    "    [\n",
    "      layers.Rescaling(scale=scale),\n",
    "      layers.RandomFlip(flip),\n",
    "      layers.RandomRotation(rotation_factor),\n",
    "      layers.RandomZoom(height_factor=zoom_height_factor, width_factor=zoom_width_factor),\n",
    "    ],\n",
    "    name='data_augmentation'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Initialising the CNN\n",
    "convolution_seq = keras.Sequential(\n",
    "    [\n",
    "      layers.Conv2D(64, (3, 3), activation = 'relu', padding='same', kernel_initializer='random_normal'),\n",
    "      layers.MaxPooling2D(pool_size = (2, 2)),\n",
    "      layers.Conv2D(64, (5, 5), activation = 'relu', padding='same', kernel_initializer='random_normal')\n",
    "    ],\n",
    "    name='convolution_net'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myLayers.vision_transformer import add_vit\n",
    "from myLayers.mlp import mlp\n",
    "\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "augmented = data_augmentation_seq(inputs)\n",
    "cnn = convolution_seq(augmented)\n",
    "features = add_vit(cnn,\n",
    "            patch_size=patch_size,\n",
    "            input_image_size=cnn.shape[1],\n",
    "            transformer_layers=transformer_layers,\n",
    "            num_heads=num_heads,\n",
    "            projection_dim=projection_dim,\n",
    "            transformer_units_rate=transformer_units_rate,\n",
    "            mlp_head_units=mlp_head_units)\n",
    "# Classify outputs.\n",
    "softmax = layers.Dense(3, activation='softmax', kernel_initializer='random_normal')(features)\n",
    "\n",
    "# Create the Keras model.\n",
    "model = keras.Model(inputs=inputs, outputs=softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_exp.standard import run_experiment\n",
    "\n",
    "checkpoint_filepath = os.path.join(output_path, \"checkpoint_cnn_transformer\")\n",
    "run_experiment(model,\n",
    "              ds_train, ds_test, ds_valid,\n",
    "              batch_size=batch_size, num_epochs=num_epochs,\n",
    "              learning_rate=learning_rate, weight_decay=weight_decay,\n",
    "              checkpoint_filepath=checkpoint_filepath,\n",
    "              from_logits=False, label_smoothing=label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid-19-xRay-gI8RPtYc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 15 2022, 05:25:54) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec449b28ee1275c8ed3472cdab9bc054b62d41bc2731e9c066fdcbfc125fb022"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
